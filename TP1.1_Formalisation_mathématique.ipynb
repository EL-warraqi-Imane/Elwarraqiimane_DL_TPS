{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "37odMBPjHyob"
   },
   "source": [
    "# *TP1 - DEEP LEARNING*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <td style=\"text-align:left\"><strong>Pr√©par√© par :</strong> EL Warraqi Imane</td>\n",
    "    <td style=\"text-align:right\"><strong>Encadr√© par :</strong> Pr. HAMZA EL KHALFI </td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tghqWAdqHyob"
   },
   "source": [
    "# Partie 1 : _Formalisation math√©matique_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour appliquer un r√©seau de neurones √† un probl√®me de machine learning (en apprentissage supervis√©),\n",
    "on a besoin de 4 choses :\n",
    "\n",
    "- Un jeu de donn√©es annot√© et un probl√®me associ√© ;\n",
    "- Une architecture de r√©seau (√† adapter aux donn√©es) ;\n",
    "- Une fonction de co√ªt que l‚Äôon cherche √† minimiser (√† adapter au probl√®me) ;\n",
    "- Un algorithme d‚Äôapprentissage pour r√©soudre le probl√®me d‚Äôoptimisation consistant √† minimiser\n",
    "cette fonction de co√ªt.\n",
    "\n",
    "On s'int√©resse ici √† un probl√®me de classification en apprentissage supervis√©. On a donc un jeu de donn√©es constitu√© d'un ensemble de $N$ couples $ (x^{(i)}, y^{(i)}) $, o√π $ i \\in \\{1, ..., N\\} $, $ x^{(i)} \\in \\mathbb{R}^{n_x} $ est un vecteur de _features_ √† partir duquel on veut pr√©dire la v√©rit√© terrain $ y^{(i)} \\in \\{0, 1\\}^{n_y} $ v√©rifiant $ \\|y^{(i)}\\| = 1 $ (_one hot encoding_). \n",
    "\n",
    "Ce jeu de donn√©es est g√©n√©ralement d√©coup√© en plusieurs ensembles : **train**, **test** et parfois **val**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3744XSfKHyob"
   },
   "source": [
    "### Q1. A quoi servent les ensembles d‚Äôapprentissage, de validation et de test ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Ensemble** | **R√¥le principal** | **Explication** | **Exemple** |\n",
    "|---------------|--------------------|------------------|--------------|\n",
    "|**Train** | Apprendre | Sert √† entra√Æner le mod√®le √† reconna√Ætre les relations entre les donn√©es d‚Äôentr√©e et la sortie attendue. | Le mod√®le apprend √† distinguer des images de pommes et de bananes. |\n",
    "| **Validation** | Ajuster et v√©rifier | Sert √† √©valuer le mod√®le pendant l‚Äôentra√Ænement et √† ajuster ses hyperparam√®tres pour √©viter le surapprentissage. | On teste le mod√®le sur de nouvelles images qu‚Äôil n‚Äôa pas encore vues. |\n",
    "| **Test** | √âvaluer la performance finale | Sert √† mesurer la capacit√© du mod√®le √† g√©n√©raliser sur des donn√©es totalement nouvelles. | On √©value la pr√©cision du mod√®le sur des images in√©dites apr√®s l‚Äôentra√Ænement. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PAMIxCJWHyoc"
   },
   "source": [
    "### Q2. Quelle est l‚Äôinfluence du nombre $N$ d‚Äôexemples ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Taille du jeu de donn√©es (N)** | **Effet sur le mod√®le** | **Avantages / Inconv√©nients** | **Exemple** |\n",
    "|----------------------------------|--------------------------|--------------------------------|--------------|\n",
    "| **Petite (N faible)** | Le mod√®le apprend mal ou surapprend les rares exemples | + Entra√Ænement rapide<br>- Mauvaise g√©n√©ralisation | 50 images de chiffres ‚Üí mauvaise reconnaissance |\n",
    "| **Grande (N √©lev√©)** | Le mod√®le apprend mieux les motifs g√©n√©raux | + Bonne g√©n√©ralisation<br>- Temps d‚Äôentra√Ænement long | 60 000 images de chiffres ‚Üí tr√®s bonne pr√©cision |\n",
    "| **Trop grande ou bruit√©e** | Le mod√®le apprend du bruit inutile | - Donn√©es redondantes, plus de calculs inutiles | Donn√©es mal √©tiquet√©es ‚Üí mod√®le confus |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mnlVKmAPHyoc"
   },
   "source": [
    "#### Q3. Pourquoi est-il important d‚Äôajouter des fonctions d‚Äôactivation entre des transformations lineaires ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Les fonctions d‚Äôactivation rendent le r√©seau non-lin√©aire.\n",
    "\n",
    "- Sans elles, plusieurs couches lin√©aires successives se r√©duiraient √† une seule transformation lin√©aire, incapable d‚Äôapprendre des relations complexes.\n",
    "\n",
    "- Elles permettent √©galement de limiter l‚Äôintervalle des sorties d‚Äôune couche (ex : tanh ‚àà [-1, 1], sigmoid ‚àà [0, 1]).\n",
    "\n",
    "## Exemples de fonctions d‚Äôactivation :\n",
    "\n",
    "- ReLU : max(0, x)\n",
    "\n",
    "- tanh : [-1, 1]\n",
    "\n",
    "- sigmoid : [0, 1]\n",
    "\n",
    "- SoftMax : [0, 1], somme = 1 (probabilit√©s)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "| **Cas** | **Description** | **Cons√©quence sur le mod√®le** | **Exemple** |\n",
    "|----------|-----------------|-------------------------------|--------------|\n",
    "| **Sans fonction d‚Äôactivation** | Le r√©seau applique seulement des transformations lin√©aires (combinaisons de droites). | Mod√®le trop simple, ne peut pas apprendre des relations complexes. | Impossible de s√©parer des cercles ou des spirales. |\n",
    "| **Avec fonction d‚Äôactivation** | Introduction de non-lin√©arit√© entre les couches. | Le mod√®le apprend des relations complexes et non lin√©aires. | Peut reconna√Ætre des visages, des formes ou des √©motions. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HoFD1mF5Hyoe"
   },
   "source": [
    "#### Q4. Quelles sont les tailles $ n_{x}, n_{h}, n_{y} $ sur la figure 1  ? En pratique, comment ces tailles sont-elles choisies ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tailles observ√©es sur la figure\n",
    "\n",
    "- **n‚Çì = 2** : La couche d‚Äôentr√©e contient **2 neurones** ‚Üí *(x‚ÇÅ, x‚ÇÇ)*  \n",
    "- **n‚Çï = 4** : La couche cach√©e contient **4 neurones** ‚Üí *(h‚ÇÅ, h‚ÇÇ, h‚ÇÉ, h‚ÇÑ)*  \n",
    "- **n·µß = 2** : La couche de sortie contient **2 neurones** ‚Üí *(≈∑‚ÇÅ, ≈∑‚ÇÇ)*\n",
    "### Choix des tailles en pratique\n",
    "\n",
    "#### üîπ Pour **n‚Çì** (entr√©e)\n",
    "- Cette taille est **impos√©e par les donn√©es**.  \n",
    "- Elle correspond au **nombre de caract√©ristiques (features)** de chaque exemple d'entra√Ænement.  \n",
    "-  Exemple : pour une image de **28√ó28 pixels**,  \n",
    "  ‚Üí **n‚Çì = 784**\n",
    "\n",
    "---\n",
    "\n",
    "#### üîπ Pour **n·µß** (sortie)\n",
    "- Cette taille d√©pend du **type de t√¢che** :\n",
    "\n",
    "| Type de t√¢che | Taille de sortie |\n",
    "|----------------|------------------|\n",
    "| Classification binaire | **n·µß = 1** |\n",
    "| Classification multi-classes avec *k* classes | **n·µß = k** |\n",
    "| R√©gression avec plusieurs valeurs √† pr√©dire | **n·µß =** nombre de sorties souhait√©es |\n",
    "\n",
    "---\n",
    "\n",
    "#### üîπ Pour **n‚Çï** (couche cach√©e)\n",
    "- C‚Äôest un **hyperparam√®tre √† choisir** (ou √† optimiser).  \n",
    "- Le choix d√©pend de plusieurs facteurs :\n",
    "  - La **complexit√© du probl√®me** : plus le probl√®me est complexe, plus on peut avoir besoin de neurones.  \n",
    "  - La **quantit√© de donn√©es** : trop de neurones avec peu de donn√©es ‚Üí risque de **surapprentissage**.  \n",
    "- üí° R√®gles empiriques :\n",
    "  - Choisir **n‚Çï** entre **n‚Çì** et **n·µß**  \n",
    "  - Ou utiliser la formule :  \n",
    "    $$\n",
    "    n‚Çï = \\frac{2}{3}(n‚Çì + n·µß)\n",
    "    $$\n",
    "- En pratique, on teste plusieurs valeurs par **validation crois√©e** ou sur un **ensemble de validation**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sl8NKiWIHyoe"
   },
   "source": [
    "#### Q5. Que repr√©sentent les vecteurs $ y $ et $ \\hat{y} $ ? Quelle est la diff√©rence entre ces deux quantit√©s ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Vecteur | Description | Exemple |\n",
    "|---------|-------------|---------|\n",
    "| **y** | Vecteur de v√©rit√© terrain (r√©el) | [0, 1] pour une classe 2 |\n",
    "| **≈∑** | Vecteur pr√©dit par le mod√®le | [0.2, 0.8] |\n",
    "| **Diff√©rence** | y vs ≈∑ ‚Üí utilis√©e pour calculer la perte | Mesurer l‚Äôerreur et ajuster les poids du r√©seau |\n",
    "- La diff√©rence entre y et ≈∑ est utilis√©e pour calculer la perte et ajuster les poids du r√©seau."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BIED5B0SHyof"
   },
   "source": [
    "#### Q6. Pourquoi utiliser une fonction $ SoftMax $ en sortie ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SoftMax transforme les sorties en probabilit√©s : chaque composante ‚àà [0, 1], et la somme = 1.\n",
    "\n",
    "- Permet d‚Äôinterpr√©ter les sorties comme la probabilit√© d‚Äôappartenance √† chaque classe.\n",
    "\n",
    "- Indispensable pour les probl√®mes de classification multi-classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hZIbE0MuHyof"
   },
   "source": [
    "#### Q7. √âcrire les √©quations math√©matiques permettant d'effectuer la passe forward du r√©seau de neurones, produisant successivement $ \\tilde{h}, \\hat{h}, \\tilde{y}, $ et $ \\hat{y} $ √† partir de $ x $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Soit :\n",
    "\n",
    "- $x \\in \\mathbb{R}^{n_x}$ : vecteur d'entr√©e  \n",
    "- $W_h \\in \\mathbb{R}^{n_h \\times n_x}, \\; b_h \\in \\mathbb{R}^{n_h}$ : poids et biais de la couche cach√©e  \n",
    "- $W_y \\in \\mathbb{R}^{n_y \\times n_h}, \\; b_y \\in \\mathbb{R}^{n_y}$ : poids et biais de la couche de sortie\n",
    "\n",
    "\n",
    "1. **Couche cach√©e : transformation lin√©aire**\n",
    "$$\n",
    "\\tilde{h} = W_h x + b_h\n",
    "$$\n",
    "\n",
    "2. **Activation tanh**\n",
    "$$\n",
    "h = \\tanh(\\tilde{h})\n",
    "$$\n",
    "\n",
    "3. **Couche de sortie : transformation lin√©aire**\n",
    "$$\n",
    "\\tilde{y} = W_y h + b_y\n",
    "$$\n",
    "\n",
    "4. **Activation SoftMax**\n",
    "$$\n",
    "\\hat{y}_i = \\frac{\\exp(\\tilde{y}_i)}{\\sum_{j=1}^{n_y} \\exp(\\tilde{y}_j)}, \\quad i = 1, \\dots, n_y\n",
    "$$\n",
    "\n",
    "- √Ä chaque √©tape, on passe d‚Äôun vecteur √† un autre :  \n",
    "$$\n",
    "x \\;\\;\\xrightarrow{W_h, b_h}\\;\\; \\tilde{h} \\;\\;\\xrightarrow{\\tanh}\\;\\; h \\;\\;\\xrightarrow{W_y, b_y}\\;\\; \\tilde{y} \\;\\;\\xrightarrow{\\text{SoftMax}}\\;\\; \\hat{y}\n",
    "$$\n",
    "\n",
    "- Le vecteur final $\\hat{y}$ est la **pr√©diction du r√©seau**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0EyKp7e_Hyof"
   },
   "source": [
    "#### Q8. Pendant l‚Äôapprentissage, on cherche √† minimiser la fonction de co√ªt. Pour l‚Äôentropie crois√©e et l‚Äôerreur quadratique, comment les $ \\hat{y}_i $ doivent-ils varier pour faire diminuer la loss ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1Ô∏è. Entropie crois√©e (Cross-Entropy) ‚Äî classification\n",
    "- Fonction :\n",
    "$$\n",
    "\\mathcal{L}(y, \\hat{y}) = - \\sum_i y_i \\log \\hat{y}_i\n",
    "$$\n",
    "- Pour minimiser la loss : \n",
    "  - $\\hat{y}_i$ pour la **classe correcte** doit tendre vers 1\n",
    "  - Les autres $\\hat{y}_j$ doivent tendre vers 0\n",
    "\n",
    " Exemple :  \n",
    "- Classe correcte = 2 ‚Üí $y = [0, 1, 0]$  \n",
    "- Sortie pr√©dite $\\hat{y} = [0.1, 0.7, 0.2]$  \n",
    "- La loss diminue si $\\hat{y}_2 \\to 1$ et $\\hat{y}_1, \\hat{y}_3 \\to 0$\n",
    "\n",
    "#### 2Ô∏è. Erreur quadratique (MSE) ‚Äî r√©gression\n",
    "- Fonction :\n",
    "$$\n",
    "\\mathcal{L}(y, \\hat{y}) = \\| y - \\hat{y} \\|_2^2 = \\sum_i (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "- Pour minimiser la loss : chaque $\\hat{y}_i$ doit se rapprocher de $y_i$\n",
    "\n",
    " Exemple :  \n",
    "- $y = 3$, $\\hat{y} = 2.5$ ‚Üí erreur = $(3 - 2.5)^2 = 0.25$  \n",
    "- Pour diminuer la loss, $\\hat{y} \\to 3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v0WWLSBUHyof"
   },
   "source": [
    "#### Q9. En quoi ces fonctions sont-elles plus adapt√©es aux probl√®mes de classification ou de r√©gression ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Fonction de co√ªt | Type de probl√®me | Pourquoi adapt√©e |\n",
    "|-----------------|-----------------|-----------------|\n",
    "| Entropie crois√©e | Classification | Sorties probabilistes (SoftMax), p√©nalise fortement les pr√©dictions incorrectes |\n",
    "| Erreur quadratique (MSE) | R√©gression | Mesure directement la distance entre la pr√©diction et la valeur r√©elle, adapt√©e aux sorties continues |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "moNmwesbHyof"
   },
   "source": [
    "#### Q10. Quels semblent etre les avantages et inconvenients des diverses variantes de descente de gradient entre les versions classique, stochastique sur mini-batch et stochastique online ? Laquelle semble la plus raisonnable a utiliser dans le cas general ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "| Variante | Avantages | Inconv√©nients |\n",
    "|----------|-----------|---------------|\n",
    "| **Batch (classique)** | Gradient exact sur l‚Äôensemble du train, convergence stable | Tr√®s co√ªteux en m√©moire et calcul si N grand, lent par it√©ration |\n",
    "| **Stochastique mini-batch (SGD)** | Compromis vitesse/stabilit√©, utilisable sur grands datasets, r√©gularisation par bruit | Gradient moins exact √† chaque pas |\n",
    "| **Stochastique online (1 exemple)** | Tr√®s rapide par it√©ration, peut sortir des minima locaux | Tr√®s bruit√© ‚Üí convergence instable |\n",
    "\n",
    "üí° **Choix pratique :** mini-batch (ex: 32 ou 64 exemples) est g√©n√©ralement pr√©f√©r√©.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q11. Quelle est l‚Äôinfluence du learning rate $ Œ∑ $ sur l‚Äôapprentissage ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Petit $\\eta$ : convergence lente mais stable  \n",
    "- Grand $\\eta$ : convergence rapide mais risque de divergence ou oscillations  \n",
    "- Choix de $\\eta$ souvent effectu√© via validation ou scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q12. Comparer la complexit√© (en fonction du nombre de couches du r√©seau)  du calcul des gradients de la loss par rapport aux param√®tres, en utilisant l'approche na√Øve et l'algorithme de l‚Äôalgorithme de backprop ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **Approche na√Øve** : recalculer le gradient depuis la loss pour chaque param√®tre ‚Üí complexit√© $\\mathcal{O}(L \\cdot N)$  \n",
    "- **Backpropagation** : r√©utilisation des gradients calcul√©s ‚Üí complexit√© lin√©aire $\\mathcal{O}(L)$ par exemple   o√π L = nombre de couches.\n",
    "\n",
    "üí° Backprop est beaucoup plus efficace pour les r√©seaux profonds.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q13. Quel crit√®re doit respecter l‚Äôarchitecture du r√©seau pour permettre la backpropagation ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Les fonctions doivent √™tre **diff√©rentiables**  \n",
    "- Chaque op√©ration doit permettre de calculer son **gradient local** (r√®gle de la cha√Æne)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q14. La fonction $ SoftMax $ et la loss de cross-entropy sont souvent utilis√©es ensemble et leur gradient est tr√®s simple. Montrez que la loss se simplifie en :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D√©monstration : simplification de la cross-entropy avec SoftMax\n",
    "\n",
    "Soit :\n",
    "\n",
    "- La sortie interm√©diaire du r√©seau : $\\tilde{y} = [\\tilde{y}_1, \\tilde{y}_2, ..., \\tilde{y}_{n_y}]$\n",
    "- La sortie pr√©dite apr√®s SoftMax :  \n",
    "$$\n",
    "\\hat{y}_i = \\frac{e^{\\tilde{y}_i}}{\\sum_j e^{\\tilde{y}_j}}\n",
    "$$\n",
    "- Le vecteur cible one-hot : $y = [y_1, y_2, ..., y_{n_y}]$  \n",
    "\n",
    "La fonction de loss cross-entropy est :\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(y, \\hat{y}) = - \\sum_i y_i \\log \\hat{y}_i\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### √âtape 1 : Remplacer $\\hat{y}_i$ par sa d√©finition SoftMax\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(y, \\hat{y}) = - \\sum_i y_i \\log \\left( \\frac{e^{\\tilde{y}_i}}{\\sum_j e^{\\tilde{y}_j}} \\right)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### √âtape 2 : Utiliser la propri√©t√© $\\log(a/b) = \\log a - \\log b$\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(y, \\hat{y}) = - \\sum_i y_i \\left( \\log e^{\\tilde{y}_i} - \\log \\sum_j e^{\\tilde{y}_j} \\right)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### √âtape 3 : Simplifier $\\log e^{\\tilde{y}_i} = \\tilde{y}_i$\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(y, \\hat{y}) = - \\sum_i y_i \\left( \\tilde{y}_i - \\log \\sum_j e^{\\tilde{y}_j} \\right)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### √âtape 4 : Distribuer le $y_i$ et la somme\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(y, \\hat{y}) = - \\sum_i y_i \\tilde{y}_i + \\sum_i y_i \\log \\sum_j e^{\\tilde{y}_j}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### √âtape 5 : Simplifier la deuxi√®me somme\n",
    "\n",
    "- Comme $y$ est un **vecteur one-hot**, on a $\\sum_i y_i = 1$  \n",
    "- Donc :  \n",
    "$$\n",
    "\\sum_i y_i \\log \\sum_j e^{\\tilde{y}_j} = \\log \\sum_j e^{\\tilde{y}_j}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "####  Conclusion\n",
    "\n",
    "La cross-entropy avec SoftMax se simplifie alors en :\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(y, \\hat{y}) = - \\sum_i y_i \\tilde{y}_i + \\log \\sum_j e^{\\tilde{y}_j}\n",
    "$$\n",
    "\n",
    "Cette forme est beaucoup plus simple √† diff√©rencier et est utilis√©e pour calculer le gradient directement lors de la backpropagation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q15. √âcrire le gradient de la loss (cross-entropy) par rapport √† la sortie interm√©diaire $\\tilde{y}$ :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial \\tilde{y}_i} = \\hat{y}_i - y_i\n",
    "$$\n",
    "\n",
    "ou en vecteur :  \n",
    "\n",
    "$$\n",
    "r_{\\tilde{y}} = \\hat{y} - y\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q16. Gradient par rapport aux poids et biais de la couche de sortie\n",
    "\n",
    "- Poids :  \n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial W_y} = r_{\\tilde{y}} \\cdot h^T\n",
    "$$\n",
    "\n",
    "- Biais :  \n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial b_y} = r_{\\tilde{y}}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Q17. Gradients de la couche cach√©e\n",
    "\n",
    "- Gradient par rapport √† la sortie cach√©e $h$ :  \n",
    "$$\n",
    "r_h = W_y^T \\cdot r_{\\tilde{y}} \\odot (1 - h^2) \\quad \\text{(pour tanh)}\n",
    "$$\n",
    "\n",
    "- Gradient par rapport aux poids et biais de la couche cach√©e :  \n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial W_h} = r_h \\cdot x^T\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial b_h} = r_h\n",
    "$$\n",
    "\n",
    "> Ici $\\odot$ repr√©sente la **multiplication √©l√©ment par √©l√©ment**."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
